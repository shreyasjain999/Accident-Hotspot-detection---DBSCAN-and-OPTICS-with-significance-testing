{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from functools import partial\n",
    "from shapely.ops import transform\n",
    "import pyproj\n",
    "import math\n",
    "from shapely.ops import cascaded_union\n",
    "from sklearn.cluster import DBSCAN\n",
    "import mplleaflet\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    #Loads the CSV files and appends them into a single DataFrame\n",
    "    column_types = {'Accident_Index': np.string_, 'LSOA_of_Accident_Location': np.string_}\n",
    "    data13 = pd.read_csv('/home/shreyas/Desktop/major2/data/DfTRoadSafety_Accidents_2013.csv', dtype=column_types)\n",
    "    data14 = pd.read_csv('/home/shreyas/Desktop/major2/data/DfTRoadSafety_Accidents_2014.csv', dtype=column_types)\n",
    "    data15 = pd.read_csv('/home/shreyas/Desktop/major2/data/DfTRoadSafety_Accidents_2015.csv', dtype=column_types)\n",
    "    data16 = pd.read_csv('/home/shreyas/Desktop/major2/data/DftRoadSafety_Accidents_2016.csv', dtype=column_types)\n",
    "    return data16.append(data15.append(data14.append(data13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def buffer_in_meters(lng, lat, radius):\n",
    "    proj_meters = pyproj.Proj(init='epsg:3857')\n",
    "    proj_latlng = pyproj.Proj(init='epsg:4326')\n",
    "    \n",
    "    project_to_meters = partial(pyproj.transform, proj_latlng, proj_meters)\n",
    "    project_to_latlng = partial(pyproj.transform, proj_meters, proj_latlng)\n",
    "    \n",
    "    pt_latlng = Point(lng, lat)\n",
    "    pt_meters = transform(project_to_meters, pt_latlng)\n",
    "    \n",
    "    buffer_meters = pt_meters.buffer(radius)\n",
    "    buffer_latlng = transform(project_to_latlng, buffer_meters)\n",
    "    return buffer_latlng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concave_hull(points, k):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[pd.to_numeric(data['Latitude'], errors='coerce').notnull()]  \n",
    "data=data[pd.to_numeric(data['Longitude'], errors='coerce').notnull()] \n",
    "data.Latitude.astype('float64')\n",
    "data.Longitude.astype('float64')\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.index)             #data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the radian longitude and latitude columns\n",
    "\n",
    "\n",
    "data['rad_lng'] = data['Longitude'] * math.pi / 180.0\n",
    "data['rad_lat'] = data['Latitude'] * math.pi / 180.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_in_meters = 50.0\n",
    "num_samples = 10\n",
    "earth_perimeter = 40070000.0  # In meters\n",
    "eps_in_radians = eps_in_meters / earth_perimeter * (2 * math.pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data['cluster'] = DBSCAN(eps=eps_in_radians, min_samples=num_samples, metric='haversine').fit_predict(data[['rad_lat', 'rad_lng']])\n",
    "fig = px.scatter(data[['rad_lat', 'rad_lng']], x=\"rad_lat\", y=\"rad_lng\")\n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= data['cluster'].to_frame()['cluster'].to_numpy()   #Dataframe to numpy array\n",
    "print(labels)\n",
    "print(len(labels))\n",
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print all the unique cluster number with no data points it includes          \n",
    "\n",
    "#Then get the frequency count of the non-negative labels\n",
    "counts = np.bincount(labels[labels>=0])\n",
    "\n",
    "print (counts)\n",
    "#print(len(counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amax(counts) #Largest cluster size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters=len(set(labels)) #no of clusters\n",
    "print(len(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels=set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get colors and plot all the points, color-coded by cluster (or gray if not in any cluster, aka noise)\n",
    "fig, ax = plt.subplots()\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_labels)))\n",
    "coords = data[[\"Latitude\", \"Longitude\"]].values\n",
    "for cluster_label, color in zip(unique_labels, colors):\n",
    "    \n",
    "    size = 100\n",
    "    if cluster_label == -1: #make the noise (which is labeled -1) appear as smaller gray points\n",
    "        color='ivory'\n",
    "        size=0\n",
    "    \n",
    "    # plot the points that match the current cluster label\n",
    "    x_coords = coords[labels==cluster_label][:,1]\n",
    "    y_coords = coords[labels==cluster_label][:,0]\n",
    "    ax.scatter(x=x_coords, y=y_coords, c=color, edgecolor='k', s=size, alpha=0.5)\n",
    "\n",
    "ax.set_title('Number of clusters: {}'.format(num_clusters))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MONTE CARLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: Significant DBSCAN towards Statistically Robust Clustering \n",
    "https://dl.acm.org/doi/pdf/10.1145/3340964.3340968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Monte",
     "Carlo"
    ]
   },
   "outputs": [],
   "source": [
    "max_size=[]\n",
    "alpha=0.02     #Significance level     #choosen on the basis of hit n trial\n",
    "M=1000         #No. of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(M):\n",
    "    random_subset=data.sample(n=400000)  \n",
    "    random_subset['cluster']=DBSCAN(eps=eps_in_radians, min_samples=num_samples, metric='haversine').fit_predict(random_subset[['rad_lat', 'rad_lng']])\n",
    "    labels=random_subset['cluster'].to_frame()['cluster'].to_numpy()\n",
    "    count=np.bincount(labels[labels>=0])\n",
    "    print(len(set(labels))) #No. of cluster in every iterations\n",
    "    maximum = np.amax(count)\n",
    "    max_size.append(maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size.sort(reverse=True)\n",
    "max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Threshold = max_size[math.ceil(alpha*M)]\n",
    "print(Threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=[]                #stores labels of all the clusters having size > Threshold\n",
    "for i in range(len(counts)):\n",
    "    if(counts[i]>Threshold):\n",
    "        idx.append(i)\n",
    "print(len(idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF=pd.DataFrame() #creates a new dataframe that's empty\n",
    "for i in range(len(idx)):\n",
    "    select_cluster=data.loc[data['cluster']==idx[i]]     #Adding all those points which belong to cluster having size > Threshold\n",
    "    #print (select_cluster)\n",
    "    newDF=newDF.append(select_cluster,ignore_index=True) # ignoring index is optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(newDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting all the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the observations by cluster identifier\n",
    "Groups=data.groupby('cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create the list of cluster blobs\n",
    "\n",
    "\n",
    "cluster=list()\n",
    "blob=list()\n",
    "freq=list()\n",
    "\n",
    "for cluster_id, points in Groups:\n",
    "    if cluster_id >= 0:\n",
    "        buffer_radius=eps_in_meters * 0.6\n",
    "        buffers=[buffer_in_meters(lon,lat,buffer_radius) for lon, lat in zip(points['Longitude'], points['Latitude'])]\n",
    "        blobs=cascaded_union(buffers)\n",
    "        blob.append(blobs)\n",
    "        cluster.append(cluster_id)\n",
    "        freq.append(len(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GeoDataFrame from the cluster numbers and blobs\n",
    "data={'cluster':cluster,'polygon':blob,'count':freq}\n",
    "\n",
    "cluster_gdf=gpd.GeoDataFrame(pd.DataFrame(data), geometry='polygon')\n",
    "cluster_gdf.crs={'init': 'epsg:4326'}\n",
    "\n",
    "img=cluster_gdf.geometry.plot(linewidth=2.0, color='red', edgecolor='red')\n",
    "\n",
    "#clusters with red borders and colors\n",
    "mplleaflet.show(fig=img.figure, tiles='cartodb_positron',path='DB_red.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "my_colors = []\n",
    "\n",
    "for i in range(4000):\n",
    "    my_colors.append('#%06X' % randint(0, 0xFFFFFF))#Generating colors array for mapping them to different clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Different clusters with different colors\n",
    "cmap = LinearSegmentedColormap.from_list('my cmap', my_colors)\n",
    "img1 = cluster_gdf.plot(column='cluster', cmap=cmap)\n",
    "mplleaflet.show(fig=img1.figure,  tiles='cartodb_positron', path='DB_colored.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the significant clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the observations by cluster identifier\n",
    "Groups=newDF.groupby('cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create the list of cluster blobs\n",
    "\n",
    "\n",
    "cluster=list()\n",
    "blob=list()\n",
    "freq=list()\n",
    "\n",
    "for cluster_id, points in Groups:\n",
    "    if cluster_id >= 0:\n",
    "        buffer_radius=eps_in_meters * 0.6\n",
    "        buffers=[buffer_in_meters(lon,lat,buffer_radius) for lon, lat in zip(points['Longitude'], points['Latitude'])]\n",
    "        blobs=cascaded_union(buffers)\n",
    "        blob.append(blobs)\n",
    "        cluster.append(cluster_id)\n",
    "        freq.append(len(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GeoDataFrame from the cluster numbers and blobs\n",
    "data={'cluster':cluster,'polygon':blob,'count':freq}\n",
    "\n",
    "cluster_gdf=gpd.GeoDataFrame(pd.DataFrame(data), geometry='polygon')\n",
    "cluster_gdf.crs={'init': 'epsg:4326'}\n",
    "\n",
    "img2=cluster_gdf.geometry.plot(linewidth=2.0, color='red', edgecolor='red')\n",
    "\n",
    "#Clusters with red borders and colors\n",
    "mplleaflet.show(fig=img2.figure, tiles='cartodb_positron',path='DB_Significant_red.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Different clusters with different colors\n",
    "cmap=LinearSegmentedColormap.from_list('my cmap', my_colors)\n",
    "img3=cluster_gdf.plot(column='cluster', cmap=cmap)\n",
    "mplleaflet.show(fig=img3.figure,tiles='cartodb_positron',path='DB_Significant_colored.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
